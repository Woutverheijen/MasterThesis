{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f901322a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-tabnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195b6749",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    ")\n",
    "from copy import deepcopy\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "FRIDAY_PATH = \"Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"\n",
    "WEDNESDAY_PATH = \"Wednesday-workingHours.pcap_ISCX.csv\"\n",
    "\n",
    "df_fri = pd.read_csv(FRIDAY_PATH)\n",
    "df_wed = pd.read_csv(WEDNESDAY_PATH)\n",
    "\n",
    "data = pd.concat([df_fri, df_wed], ignore_index=True)\n",
    "print(f\"Combined shape: {data.shape}\")\n",
    "\n",
    "#Data Prepocessing\n",
    "data.columns = data.columns.str.strip()\n",
    "if 'Label' not in data.columns:\n",
    "    raise ValueError(\"Expected 'Label' column not found.\")\n",
    "\n",
    "print(\"Unique labels before binary encoding:\")\n",
    "print(data['Label'].unique())\n",
    "\n",
    "data['Label'] = data['Label'].astype(str).str.strip()\n",
    "data['Label'] = data['Label'].apply(lambda x: 0 if x == \"BENIGN\" else 1)\n",
    "\n",
    "print(\"\\nBinary label distribution (0=BENIGN, 1=ATTACK):\")\n",
    "print(data['Label'].value_counts())\n",
    "\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "before = data.shape[0]\n",
    "data.dropna(inplace=True)\n",
    "after = data.shape[0]\n",
    "\n",
    "print(f\"\\nDropped {before - after} rows due to NaN/inf values.\")\n",
    "print(f\"Remaining rows: {after}\")\n",
    "\n",
    "zero_var_cols = [c for c in data.columns if c != 'Label' and data[c].nunique() <= 1]\n",
    "if zero_var_cols:\n",
    "    print(\"Dropping zero-variance columns:\", zero_var_cols)\n",
    "    data.drop(columns=zero_var_cols, inplace=True)\n",
    "\n",
    "feature_names = [c for c in data.columns if c != 'Label']\n",
    "X = data[feature_names].values\n",
    "y = data['Label'].values\n",
    "\n",
    "print(f\"\\nFinal feature count: {len(feature_names)}\")\n",
    "print(f\"Final dataset size  : {data.shape[0]} rows\")\n",
    "\n",
    "#Model Training\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=SEED, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=SEED, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Shapes -> Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n",
    "\n",
    "#Small hyperparamater search\n",
    "base_params = {\n",
    "    \"n_d\": 16,\n",
    "    \"n_a\": 16,\n",
    "    \"n_steps\": 5,\n",
    "    \"gamma\": 1.5,\n",
    "    \"n_independent\": 2,\n",
    "    \"n_shared\": 2,\n",
    "    \"momentum\": 0.02,\n",
    "    \"mask_type\": \"entmax\",\n",
    "    \"lambda_sparse\": 1e-4,\n",
    "    \"optimizer_fn\": torch.optim.Adam,\n",
    "    \"optimizer_params\": dict(lr=2e-3),\n",
    "    \"scheduler_params\": {\"step_size\": 20, \"gamma\": 0.95},\n",
    "    \"scheduler_fn\": torch.optim.lr_scheduler.StepLR,\n",
    "    \"verbose\": 0,\n",
    "}\n",
    "\n",
    "param_grid = [\n",
    "    {\n",
    "        \"name\": \"baseline_literature\",\n",
    "        \"n_d\": 16, \"n_a\": 16, \"n_steps\": 5,\n",
    "        \"gamma\": 1.5,\n",
    "        \"lambda_sparse\": 1e-4,\n",
    "        \"lr\": 2e-3,\n",
    "        \"mask_type\": \"entmax\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"shallower_faster\",\n",
    "        \"n_d\": 16, \"n_a\": 16, \"n_steps\": 3,\n",
    "        \"gamma\": 1.5,\n",
    "        \"lambda_sparse\": 1e-4,\n",
    "        \"lr\": 2e-3,\n",
    "        \"mask_type\": \"entmax\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"more_sparse_regularized\",\n",
    "        \"n_d\": 16, \"n_a\": 16, \"n_steps\": 5,\n",
    "        \"gamma\": 1.5,\n",
    "        \"lambda_sparse\": 1e-3,\n",
    "        \"lr\": 2e-3,\n",
    "        \"mask_type\": \"entmax\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"sparsemax_masks\",\n",
    "        \"n_d\": 16, \"n_a\": 16, \"n_steps\": 5,\n",
    "        \"gamma\": 1.5,\n",
    "        \"lambda_sparse\": 1e-4,\n",
    "        \"lr\": 2e-3,\n",
    "        \"mask_type\": \"sparsemax\",\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"higher_lr_quick_convergence\",\n",
    "        \"n_d\": 16, \"n_a\": 16, \"n_steps\": 5,\n",
    "        \"gamma\": 1.5,\n",
    "        \"lambda_sparse\": 1e-4,\n",
    "        \"lr\": 3e-3,\n",
    "        \"mask_type\": \"entmax\",\n",
    "    },\n",
    "]\n",
    "\n",
    "best_val_acc = -1.0\n",
    "best_name = None\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for i, pg in enumerate(param_grid, 1):\n",
    "    print(f\"\\n=== Config {i}/{len(param_grid)}: {pg['name']} ===\")\n",
    "\n",
    "    params = deepcopy(base_params)\n",
    "    params[\"n_d\"] = pg[\"n_d\"]\n",
    "    params[\"n_a\"] = pg[\"n_a\"]\n",
    "    params[\"n_steps\"] = pg[\"n_steps\"]\n",
    "    params[\"gamma\"] = pg[\"gamma\"]\n",
    "    params[\"lambda_sparse\"] = pg[\"lambda_sparse\"]\n",
    "    params[\"mask_type\"] = pg[\"mask_type\"]\n",
    "    params[\"optimizer_params\"] = dict(lr=pg[\"lr\"])\n",
    "\n",
    "    clf_tmp = TabNetClassifier(**params)\n",
    "\n",
    "    clf_tmp.fit(\n",
    "        X_train=X_train, y_train=y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        eval_name=[\"train\", \"valid\"],\n",
    "        eval_metric=[\"accuracy\"],\n",
    "        max_epochs=80,\n",
    "        patience=10,\n",
    "        batch_size=1024,\n",
    "        virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    valid_acc_hist = clf_tmp.history[\"valid_accuracy\"]\n",
    "    best_epoch = int(np.argmax(valid_acc_hist))\n",
    "    val_acc = valid_acc_hist[best_epoch]\n",
    "\n",
    "    print(f\"Best val accuracy for {pg['name']}: {val_acc:.6f} at epoch {best_epoch}\")\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_name = pg[\"name\"]\n",
    "        best_params = params\n",
    "        best_model = clf_tmp\n",
    "\n",
    "print(\"\\n=== Best configuration selected ===\")\n",
    "print(\"Name :\", best_name)\n",
    "print(\"Params:\", best_params)\n",
    "print(f\"Best validation accuracy: {best_val_acc:.6f}\")\n",
    "\n",
    "clf = best_model\n",
    "\n",
    "# Evaluation\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "prec = precision_score(y_test, y_pred, zero_division=0)\n",
    "rec = recall_score(y_test, y_pred, zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, zero_division=0)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "far = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "print(\"\\n=== TabNet – Test Metrics (Binary: 0=BENIGN, 1=ATTACK) ===\")\n",
    "print(f\"Accuracy : {acc:.4f}\")\n",
    "print(f\"Precision: {prec:.4f}\")\n",
    "print(f\"Recall   : {rec:.4f}\")\n",
    "print(f\"F1-score : {f1:.4f}\")\n",
    "print(f\"FAR      : {far:.6f}  (False Alarm Rate = FP / (FP + TN))\")\n",
    "\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(\n",
    "    cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"TabNet – Confusion Matrix (Binary)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Global Feature Importance\n",
    "global_importance = clf.feature_importances_\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": global_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 global features:\")\n",
    "print(feat_imp_df.head(10))\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feat_imp_df.head(15), x=\"Importance\", y=\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04d4a5",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "X_cv = np.concatenate([X_train, X_val])\n",
    "y_cv = np.concatenate([y_train, y_val])\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "\n",
    "cv_results = []\n",
    "fold = 0\n",
    "\n",
    "for train_idx, test_idx in skf.split(X_cv, y_cv):\n",
    "    fold += 1\n",
    "    X_tr, X_te = X_cv[train_idx], X_cv[test_idx]\n",
    "    y_tr, y_te = y_cv[train_idx], y_cv[test_idx]\n",
    "    X_tr2, X_va, y_tr2, y_va = train_test_split(\n",
    "        X_tr, y_tr,\n",
    "        test_size=0.2,\n",
    "        random_state=SEED,\n",
    "        stratify=y_tr\n",
    "    )\n",
    "\n",
    "    print(f\"\\n--- Fold {fold} ---\")\n",
    "\n",
    "    clf_fold = TabNetClassifier(**best_params)\n",
    "\n",
    "    clf_fold.fit(\n",
    "        X_train=X_tr2, y_train=y_tr2,\n",
    "        eval_set=[(X_tr2, y_tr2), (X_va, y_va)],\n",
    "        eval_name=[\"train\", \"valid\"],\n",
    "        eval_metric=[\"accuracy\"],\n",
    "        max_epochs=100,\n",
    "        patience=10,\n",
    "        batch_size=1024,\n",
    "        virtual_batch_size=128,\n",
    "        num_workers=0,\n",
    "        drop_last=False,\n",
    "    )\n",
    "\n",
    "    y_pred_fold = clf_fold.predict(X_te)\n",
    "\n",
    "    acc  = accuracy_score(y_te, y_pred_fold)\n",
    "    prec = precision_score(y_te, y_pred_fold, zero_division=0)\n",
    "    rec  = recall_score(y_te, y_pred_fold, zero_division=0)\n",
    "    f1   = f1_score(y_te, y_pred_fold, zero_division=0)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_te, y_pred_fold).ravel()\n",
    "    far = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
    "\n",
    "    print(\n",
    "        f\"Fold {fold} – \"\n",
    "        f\"Acc:{acc:.4f}, Prec:{prec:.4f}, Rec:{rec:.4f}, \"\n",
    "        f\"F1:{f1:.4f}, FAR:{far:.6f}\"\n",
    "    )\n",
    "\n",
    "    cv_results.append([acc, prec, rec, f1, far])\n",
    "\n",
    "cv_results = np.array(cv_results)\n",
    "metrics = [\"Accuracy\", \"Precision\", \"Recall\", \"F1-score\", \"FAR\"]\n",
    "\n",
    "print(\"\\n=== Cross-Validation Summary (mean ± std) ===\")\n",
    "for i, m in enumerate(metrics):\n",
    "    mean_val = cv_results[:, i].mean()\n",
    "    std_val = cv_results[:, i].std()\n",
    "    print(f\"{m:<10}: {mean_val:.4f} ± {std_val:.44f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed8a0a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Local + ClassConditional Explanations\n",
    "M_explain_test, masks = clf.explain(X_test)\n",
    "\n",
    "print(\"M_explain_test shape:\", np.array(M_explain_test).shape)\n",
    "print(\"Number of steps in masks:\", len(masks))\n",
    "print(\"One mask shape:\", np.array(masks[0]).shape if len(masks) else None)\n",
    "\n",
    "# --- Local explanations ---\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "tp_indices = np.where((y_pred == 1) & (y_test == 1))[0]\n",
    "fp_indices = np.where((y_pred == 1) & (y_test == 0))[0]\n",
    "fn_indices = np.where((y_pred == 0) & (y_test == 1))[0]\n",
    "\n",
    "example_tp = int(tp_indices[0]) if len(tp_indices) else None\n",
    "example_fp = int(fp_indices[0]) if len(fp_indices) else None\n",
    "example_fn = int(fn_indices[0]) if len(fn_indices) else None\n",
    "\n",
    "def top_k_from_vector(vec, names, k=10):\n",
    "    vec = np.asarray(vec).reshape(-1)\n",
    "    names = np.asarray(names).reshape(-1)\n",
    "    order = np.argsort(np.abs(vec))[::-1][:k]\n",
    "    return pd.DataFrame({\"Feature\": names[order], \"Attribution\": vec[order]})\n",
    "\n",
    "# True Positive\n",
    "if example_tp is not None:\n",
    "    top_tp_df = top_k_from_vector(M_explain_test[example_tp], feature_names, k=10)\n",
    "    print(\"\\nLocal explanation – Example True Positive (Top 10):\")\n",
    "    print(top_tp_df)\n",
    "\n",
    "# False Positive\n",
    "if example_fp is not None:\n",
    "    top_fp_df = top_k_from_vector(M_explain_test[example_fp], feature_names, k=10)\n",
    "    print(\"\\nLocal explanation – Example False Positive (Top 10):\")\n",
    "    print(top_fp_df)\n",
    "\n",
    "#False Negative\n",
    "if example_fn is not None:\n",
    "    top_fn_df = top_k_from_vector(M_explain_test[example_fn], feature_names, k=10)\n",
    "    print(\"\\nLocal explanation – Example False Negative (Top 10):\")\n",
    "    print(top_fn_df)\n",
    "\n",
    "#Class conditional\n",
    "mean_pos = M_explain_test[y_test == 1].mean(axis=0)\n",
    "mean_neg = M_explain_test[y_test == 0].mean(axis=0)\n",
    "\n",
    "class_imp_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Mean_Attribution_DoS_DDoS\": mean_pos,\n",
    "    \"Mean_Attribution_Benign\": mean_neg,\n",
    "    \"AbsDiff\": np.abs(mean_pos - mean_neg)\n",
    "}).sort_values(\"AbsDiff\", ascending=False)\n",
    "\n",
    "print(\"\\nTop 10 class-conditional differences:\")\n",
    "print(class_imp_df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce78704",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Improving the plots\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.size\"] = 10           \n",
    "plt.rcParams[\"axes.titlesize\"] = 11      \n",
    "plt.rcParams[\"axes.labelsize\"] = 10\n",
    "plt.rcParams[\"xtick.labelsize\"] = 9\n",
    "plt.rcParams[\"ytick.labelsize\"] = 9\n",
    "plt.rcParams[\"legend.fontsize\"] = 9\n",
    "\n",
    "\n",
    "global_importance = clf.feature_importances_\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    \"Feature\": feature_names,\n",
    "    \"Importance\": global_importance\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "top_n = 10\n",
    "top_feat = feat_imp_df.head(top_n) \n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(\n",
    "    data=top_feat,\n",
    "    x=\"Importance\",\n",
    "    y=\"Feature\",\n",
    "    hue=\"Feature\",       \n",
    "    dodge=False,\n",
    "    legend=False,\n",
    "    palette=\"Blues_r\"\n",
    ")\n",
    "\n",
    "ax.set_xlim(0, top_feat[\"Importance\"].max() * 1.1)\n",
    "\n",
    "sns.despine(top=True, right=True)\n",
    "\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if example_tp is not None:\n",
    "    top_tp_df = top_k_from_vector(M_explain_test[example_tp], feature_names, k=10)\n",
    "    top_tp_df = top_tp_df.sort_values(by=\"Attribution\", ascending=False)\n",
    "\n",
    "    print(\"\\nLocal explanation – Example TP (Top 10):\")\n",
    "    print(top_tp_df)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    ax = sns.barplot(\n",
    "        data=top_tp_df,\n",
    "        x=\"Attribution\",\n",
    "        y=\"Feature\",\n",
    "        hue=\"Feature\",\n",
    "        dodge=False,\n",
    "        legend=False,\n",
    "        palette=\"Blues_r\"\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(0, top_tp_df[\"Attribution\"].max() * 1.1)\n",
    "\n",
    "\n",
    "    plt.xlabel(\"Attribution\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "    sns.despine(top=True, right=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "if example_fp is not None:\n",
    "    top_fp_df = top_k_from_vector(M_explain_test[example_fp], feature_names, k=10)\n",
    "    top_fp_df = top_fp_df.sort_values(by=\"Attribution\", ascending=False)\n",
    "\n",
    "    print(\"\\nLocal explanation – Example FP (Top 10):\")\n",
    "    print(top_fp_df)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    ax = sns.barplot(\n",
    "        data=top_fp_df,\n",
    "        x=\"Attribution\",\n",
    "        y=\"Feature\",\n",
    "        hue=\"Feature\",\n",
    "        dodge=False,\n",
    "        legend=False,\n",
    "        palette=\"Blues_r\"\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(0, top_fp_df[\"Attribution\"].max() * 1.1)\n",
    "\n",
    "\n",
    "    plt.xlabel(\"Attribution\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "    sns.despine(top=True, right=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "top15_class = class_imp_df.head(10)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(\n",
    "    data=top15_class,\n",
    "    x=\"AbsDiff\",\n",
    "    y=\"Feature\",\n",
    "    hue=\"Feature\",        \n",
    "    dodge=False,\n",
    "    legend=False,\n",
    "    palette=\"Blues_r\"\n",
    ")\n",
    "\n",
    "\n",
    "ax.set_xlim(0, top15_class[\"AbsDiff\"].max() * 1.1)\n",
    "\n",
    "\n",
    "sns.despine(top=True, right=True) \n",
    "\n",
    "plt.xlabel(\"Absolute difference in mean attribution\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if example_fn is not None:\n",
    "    top_fn_df = top_k_from_vector(M_explain_test[example_fn], feature_names, k=10)\n",
    "    top_fn_df = top_fn_df.sort_values(by=\"Attribution\", ascending=False)\n",
    "\n",
    "    print(\"\\nLocal explanation – Example FN (Top 10):\")\n",
    "    print(top_fn_df)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    ax = sns.barplot(\n",
    "        data=top_fn_df,\n",
    "        x=\"Attribution\",\n",
    "        y=\"Feature\",\n",
    "        hue=\"Feature\",\n",
    "        dodge=False,\n",
    "        legend=False,\n",
    "        palette=\"Blues_r\"\n",
    "    )\n",
    "\n",
    "    ax.set_xlim(0, top_fn_df[\"Attribution\"].max() * 1.1)\n",
    "\n",
    "    plt.xlabel(\"Attribution\")\n",
    "    plt.ylabel(\"Feature\")\n",
    "\n",
    "    sns.despine(top=True, right=True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
